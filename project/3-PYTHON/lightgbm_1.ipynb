{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7140bf-df44-461e-af50-cea9449c0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "#from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import preprocessing\n",
    "import calendar\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce20260c-60af-40eb-b1b6-030f34fa7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"duom/train_data_1.csv\")\n",
    "test_data = pd.read_csv(\"duom/test_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed624bc-c4a2-483c-aaea-2715a8e8fec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long' 'short']\n",
      "['long' 'short']\n",
      "['fair' 'good' 'unknown' 'very_good']\n",
      "['fair' 'good' 'unknown' 'very_good']\n",
      "['business_loan' 'buy_a_car' 'buy_house' 'debt_consolidation'\n",
      " 'educational_expenses' 'home_improvements' 'major_purchase'\n",
      " 'medical_bills' 'moving' 'other' 'small_business' 'take_a_trip'\n",
      " 'vacation' 'wedding']\n",
      "['business_loan' 'buy_a_car' 'buy_house' 'debt_consolidation'\n",
      " 'educational_expenses' 'home_improvements' 'major_purchase'\n",
      " 'medical_bills' 'moving' 'other' 'small_business' 'take_a_trip'\n",
      " 'vacation' 'wedding']\n",
      "['mortgage' 'own' 'rent']\n",
      "['mortgage' 'own' 'rent']\n"
     ]
    }
   ],
   "source": [
    "le1 = preprocessing.LabelEncoder()\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "cols = ['term', 'credit_score', 'loan_purpose', 'home_ownership']\n",
    "for col in cols:\n",
    "    train_data[col] = le1.fit_transform(train_data[col])\n",
    "    test_data[col] = le2.fit_transform(test_data[col])\n",
    "    print(le1.classes_)\n",
    "    print(le2.classes_)\n",
    "\n",
    "y = train_data['y']\n",
    "x = train_data.drop(['y', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4938c19d-0668-4fdf-b065-17f0d746e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create training and validation sets\n",
    "#\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#\n",
    "# Create the LightGBM data containers\n",
    "#\n",
    "lgb_train = lgb.Dataset(x_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d0d19f6-98a6-4e57-af91-4700ac6c1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'metric': 'auc',\\n    'objective': 'binary',\\n    'learning_rate': 0.018782604994529304, \\n    'max_depth': 38, \\n    'num_leaves': 24708, \\n    'feature_fraction': 0.965292624452857, \\n    'subsample': 0.721752904462013\\nparams = {    \\n    'boosting_type': 'gbdt',\\n    'objective': 'regression',\\n    'lambda_l1': 0.00004, \\n    'lambda_l2': 0.004, \\n    'num_leaves': 40000, \\n    'feature_fraction': 0.995, \\n    'bagging_fraction': 0.974, \\n    'bagging_freq': 1, \\n    'min_child_samples': 14,\\n    'max_bin': 6000,\\n    'is_unbalace': True\\n}\\n\\nprint('Starting training...')\\n# train\\nmodel = lgb.train(params,\\n                lgb_train,\\n                num_boost_round=20,\\n                valid_sets=lgb_eval,\\n                callbacks=[lgb.early_stopping(stopping_rounds=5)])\\n\\nprint('Starting predicting...')\\n# predict\\ny_pred = model.predict(x_test, num_iteration=model.best_iteration)\\n# eval\\nrmse_test = mean_squared_error(y_test, y_pred) ** 0.5\\nprint(f'The RMSE of prediction is: {rmse_test}')\\n\\npreds = model.predict(x_test)\\npred_labels = np.rint(preds)\\naccuracy = metrics.accuracy_score(y_test, pred_labels)\\nprint(f'The ACU of prediction is: {accuracy}')\\n#0.8707655164909319\\n#0.8764131445695981\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"'metric': 'auc',\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.018782604994529304, \n",
    "    'max_depth': 38, \n",
    "    'num_leaves': 24708, \n",
    "    'feature_fraction': 0.965292624452857, \n",
    "    'subsample': 0.721752904462013\n",
    "params = {    \n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'lambda_l1': 0.00004, \n",
    "    'lambda_l2': 0.004, \n",
    "    'num_leaves': 40000, \n",
    "    'feature_fraction': 0.995, \n",
    "    'bagging_fraction': 0.974, \n",
    "    'bagging_freq': 1, \n",
    "    'min_child_samples': 14,\n",
    "    'max_bin': 6000,\n",
    "    'is_unbalace': True\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "model = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=5)])\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "# eval\n",
    "rmse_test = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f'The RMSE of prediction is: {rmse_test}')\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = metrics.accuracy_score(y_test, pred_labels)\n",
    "print(f'The ACU of prediction is: {accuracy}')\n",
    "#0.8707655164909319\n",
    "#0.8764131445695981\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c2e0f38-e34f-4d73-9c30-88b6f7d24bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1263373, number of negative: 4155746\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.227856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1541\n",
      "[LightGBM] [Info] Number of data points in the train set: 5419119, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.233133 -> initscore=-1.190707\n",
      "[LightGBM] [Info] Start training from score -1.190707\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid's auc: 0.905793\n",
      "validation AUC: 0.9057928334465929\n"
     ]
    }
   ],
   "source": [
    "SEARCH_PARAMS = {'learning_rate': 0.018782604994529304, \n",
    "                'max_depth': 38, \n",
    "                'num_leaves': 24708, \n",
    "                'feature_fraction': 0.965292624452857, \n",
    "                'subsample': 0.721752904462013}\n",
    "\n",
    "def train_evaluate(search_params):\n",
    "    params = {'objective': 'binary',\n",
    "              'metric': 'auc',\n",
    "              **search_params}\n",
    "\n",
    "    model = lgb.train(params, lgb_train,\n",
    "                      num_boost_round=500,\n",
    "                      #early_stopping_rounds=10,\n",
    "                      callbacks=[lgb.early_stopping(stopping_rounds=50)],\n",
    "                      valid_sets=lgb_eval,\n",
    "                      valid_names='valid'\n",
    "                     )\n",
    "    \n",
    "    score = model.best_score['valid']['auc']\n",
    "    return score, model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    score, model = train_evaluate(SEARCH_PARAMS)\n",
    "    print('validation AUC:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3085b2e3-294e-4f3a-9a01-9eabf641cfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_data['id'].values\n",
    "test_data = test_data.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175a6844-801f-4ccf-b9c5-4f2a174613f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.107575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.990458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.072420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.159505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.990559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.113315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.002819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.294503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.684629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.474984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.059731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.601624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.074715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    target\n",
       "0    1  0.107575\n",
       "1    2  0.990458\n",
       "2    3  0.072420\n",
       "3    4  0.159505\n",
       "4    5  0.990559\n",
       "5    6  0.113315\n",
       "6    7  0.002819\n",
       "7    8  0.294503\n",
       "8    9  0.002453\n",
       "9   10  0.684629\n",
       "10  11  0.002888\n",
       "11  12  0.474984\n",
       "12  13  0.059731\n",
       "13  14  0.601624\n",
       "14  15  0.074715"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = test_data.values\n",
    "y = model.predict(x)\n",
    "output = pd.DataFrame({'id': ids, 'target': y})\n",
    "output.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56a703e-f4c3-4cd7-a325-0eb3e7e8c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"submission_1_GBM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d895ace4-a197-4d9d-9ab8-84a234939c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f0c4ade6b90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_model('model_1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01970b26-7c88-4402-a32d-19502a8afc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import skopt\\n\\nSPACE = [\\n    skopt.space.Real(0.01, 0.5, name='learning_rate', prior='log-uniform'),\\n    skopt.space.Integer(1, 50, name='max_depth'),\\n    skopt.space.Integer(1000, 40000, name='num_leaves'),\\n    skopt.space.Real(0.1, 1.0, name='feature_fraction', prior='uniform'),\\n    skopt.space.Real(0.1, 1.0, name='subsample', prior='uniform')]\\n@skopt.utils.use_named_args(SPACE)\\ndef objective(**params):\\n    return -1.0 * train_evaluate(params)\\nresults = skopt.forest_minimize(objective, SPACE, n_calls=30, n_random_starts=10)\\nbest_auc = -1.0 * results.fun\\nbest_params = results.x\\n\\nprint('best result: ', best_auc)\\nprint('best parameters: ', best_params)\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import skopt\n",
    "\n",
    "SPACE = [\n",
    "    skopt.space.Real(0.01, 0.5, name='learning_rate', prior='log-uniform'),\n",
    "    skopt.space.Integer(1, 50, name='max_depth'),\n",
    "    skopt.space.Integer(1000, 40000, name='num_leaves'),\n",
    "    skopt.space.Real(0.1, 1.0, name='feature_fraction', prior='uniform'),\n",
    "    skopt.space.Real(0.1, 1.0, name='subsample', prior='uniform')]\n",
    "@skopt.utils.use_named_args(SPACE)\n",
    "def objective(**params):\n",
    "    return -1.0 * train_evaluate(params)\n",
    "results = skopt.forest_minimize(objective, SPACE, n_calls=30, n_random_starts=10)\n",
    "best_auc = -1.0 * results.fun\n",
    "best_params = results.x\n",
    "\n",
    "print('best result: ', best_auc)\n",
    "print('best parameters: ', best_params)\"\"\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
